{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "import mlflow.pyfunc\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "import tensorflow as tf\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "MLFLOW_TRACKING_URI=os.getenv('MLFLOW_TRACKING_URI')\n",
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "\n",
    "\n",
    "def get_tokenizer():\n",
    "    with open('./artifact/tokenizer.bin', \"rb\") as f_in:\n",
    "        tokenizer = pickle.load(f_in)\n",
    "    \n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def prepare(text):\n",
    "    maxlen = 300\n",
    "    tokenizer = get_tokenizer()\n",
    "    tokens = tokenizer.texts_to_sequences(text)\n",
    "    tokens = sequence.pad_sequences(tokens, maxlen=maxlen)\n",
    "    return tokens\n",
    "    \n",
    "def load_model():\n",
    "    uri_path = Path.cwd().joinpath('artifact/model').as_uri()\n",
    "    model = mlflow.keras.load_model(uri_path)\n",
    "    return model\n",
    "    \n",
    "\n",
    "def classify(text):\n",
    "    print(\"Loading the model...\")\n",
    "    model = load_model()\n",
    "    print(\"Successful!\")\n",
    "    preds = model.predict(text)\n",
    "    return preds\n",
    "\n",
    "\n",
    "# app = Flask('fake-news-classifier')\n",
    "\n",
    "\n",
    "# @app.route('/classify', methods=['POST'])\n",
    "def classify_endpoint(text):\n",
    "\n",
    "    prepped_text = prepare(text)\n",
    "\n",
    "    pred = classify(prepped_text)\n",
    "\n",
    "    pred = tf.argmax(pred, axis=1).numpy()\n",
    "\n",
    "    result = {\n",
    "        'text': text,\n",
    "        'class': pred\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    text = event['text']\n",
    "    prepped_text = prepare(text)\n",
    "\n",
    "    pred = classify(prepped_text)\n",
    "\n",
    "    pred = tf.argmax(pred, axis=1).numpy()[0].tolist()\n",
    "\n",
    "    result = {\n",
    "        'text': text,\n",
    "        'class': pred\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "true = pd.read_csv('./data/True.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model...\n",
      "Successful!\n",
      "146/146 [==============================] - 27s 179ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'WASHINGTON (Reuters) - The head of a conservative Republican faction in the U.S. Congress, who voted this month for a huge expansion of the national debt to pay for tax cuts, called himself a “fiscal conservative” on Sunday and urged budget restraint in 2018. In keeping with a sharp pivot under way among Republicans, U.S. Representative Mark Meadows, speaking on CBS’ “Face the Nation,” drew a hard line on federal spending, which lawmakers are bracing to do battle over in January. When they return from the holidays on Wednesday, lawmakers will begin trying to pass a federal budget in a fight likely to be linked to other issues, such as immigration policy, even as the November congressional election campaigns approach in which Republicans will seek to keep control of Congress. President Donald Trump and his Republicans want a big budget increase in military spending, while Democrats also want proportional increases for non-defense “discretionary” spending on programs that support education, scientific research, infrastructure, public health and environmental protection. “The (Trump) administration has already been willing to say: ‘We’re going to increase non-defense discretionary spending ... by about 7 percent,’” Meadows, chairman of the small but influential House Freedom Caucus, said on the program. “Now, Democrats are saying that’s not enough, we need to give the government a pay raise of 10 to 11 percent. For a fiscal conservative, I don’t see where the rationale is. ... Eventually you run out of other people’s money,” he said. Meadows was among Republicans who voted in late December for their party’s debt-financed tax overhaul, which is expected to balloon the federal budget deficit and add about $1.5 trillion over 10 years to the $20 trillion national debt. “It’s interesting to hear Mark talk about fiscal responsibility,” Democratic U.S. Representative Joseph Crowley said on CBS. Crowley said the Republican tax bill would require the  United States to borrow $1.5 trillion, to be paid off by future generations, to finance tax cuts for corporations and the rich. “This is one of the least ... fiscally responsible bills we’ve ever seen passed in the history of the House of Representatives. I think we’re going to be paying for this for many, many years to come,” Crowley said. Republicans insist the tax package, the biggest U.S. tax overhaul in more than 30 years,  will boost the economy and job growth. House Speaker Paul Ryan, who also supported the tax bill, recently went further than Meadows, making clear in a radio interview that welfare or “entitlement reform,” as the party often calls it, would be a top Republican priority in 2018. In Republican parlance, “entitlement” programs mean food stamps, housing assistance, Medicare and Medicaid health insurance for the elderly, poor and disabled, as well as other programs created by Washington to assist the needy. Democrats seized on Ryan’s early December remarks, saying they showed Republicans would try to pay for their tax overhaul by seeking spending cuts for social programs. But the goals of House Republicans may have to take a back seat to the Senate, where the votes of some Democrats will be needed to approve a budget and prevent a government shutdown. Democrats will use their leverage in the Senate, which Republicans narrowly control, to defend both discretionary non-defense programs and social spending, while tackling the issue of the “Dreamers,” people brought illegally to the country as children. Trump in September put a March 2018 expiration date on the Deferred Action for Childhood Arrivals, or DACA, program, which protects the young immigrants from deportation and provides them with work permits. The president has said in recent Twitter messages he wants funding for his proposed Mexican border wall and other immigration law changes in exchange for agreeing to help the Dreamers. Representative Debbie Dingell told CBS she did not favor linking that issue to other policy objectives, such as wall funding. “We need to do DACA clean,” she said.  On Wednesday, Trump aides will meet with congressional leaders to discuss those issues. That will be followed by a weekend of strategy sessions for Trump and Republican leaders on Jan. 6 and 7, the White House said. Trump was also scheduled to meet on Sunday with Florida Republican Governor Rick Scott, who wants more emergency aid. The House has passed an $81 billion aid package after hurricanes in Florida, Texas and Puerto Rico, and wildfires in California. The package far exceeded the $44 billion requested by the Trump administration. The Senate has not yet voted on the aid. ',\n",
       " 'class': 0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_handler({'text': true.iloc[0].text}, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "\n",
    "import mlflow.pyfunc\n",
    "\n",
    "MLFLOW_TRACKING_URI=os.environ['MLFLOW_TRACKING_URI']\n",
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "\n",
    "model_name = \"fake-news-detect-1\"\n",
    "\n",
    "model_versions = client.search_model_versions(f\"name='{model_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ModelVersion: creation_timestamp=1662027138594, current_stage='Production', description='', last_updated_timestamp=1662027803213, name='fake-news-detect-1', run_id='d92d79a7278d4408b2406d82b2b09aab', run_link='', source='s3://my-mlflow-models-bucket/d92d79a7278d4408b2406d82b2b09aab/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='2'>,\n",
       " <ModelVersion: creation_timestamp=1662026816835, current_stage='Production', description='', last_updated_timestamp=1662027839298, name='fake-news-detect-1', run_id='d92d79a7278d4408b2406d82b2b09aab', run_link='', source='s3://my-mlflow-models-bucket/d92d79a7278d4408b2406d82b2b09aab/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='1'>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model_versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/thresh/MLOPS/final_mlops_zoomcamp/artifact/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.artifacts.download_artifacts(run_id = 'd92d79a7278d4408b2406d82b2b09aab', dst_path='./artifact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/thresh/MLOPS/final_mlops_zoomcamp/testing.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B24.199.64.104/home/thresh/MLOPS/final_mlops_zoomcamp/testing.ipynb#X62sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdict\u001b[39m(client\u001b[39m.\u001b[39;49mget_latest_versions(name\u001b[39m=\u001b[39;49mmodel_name)[\u001b[39m1\u001b[39;49m])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "dict(client.get_latest_versions(name=model_name)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlflow.keras.load_model(uri_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./main/data/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/thresh/MLOPS/final_mlops_zoomcamp\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///home/thresh/MLOPS/final_mlops_zoomcamp/artifact/model'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'artifact/model/data/model'\n",
    "\n",
    "uri_path = Path.cwd().joinpath('artifact/model').as_uri()\n",
    "uri_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///home/thresh/MLOPS/final_mlops_zoomcamp/bint/main/data/model'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uri_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/thresh/MLOPS/final_mlops_zoomcamp/bint/main/data/model')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.cwd().joinpath('main/data/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../artifact/tokenizer.bin', \"rb\") as f_in:\n",
    "    tokenizer = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'creation_timestamp': 1662027138594,\n",
       " 'current_stage': 'Production',\n",
       " 'description': '',\n",
       " 'last_updated_timestamp': 1662027803213,\n",
       " 'name': 'fake-news-detect-1',\n",
       " 'run_id': 'd92d79a7278d4408b2406d82b2b09aab',\n",
       " 'run_link': '',\n",
       " 'source': 's3://my-mlflow-models-bucket/d92d79a7278d4408b2406d82b2b09aab/artifacts/model',\n",
       " 'status': 'READY',\n",
       " 'status_message': '',\n",
       " 'tags': {},\n",
       " 'user_id': '',\n",
       " 'version': '2'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mv = client.search_model_versions(\"name='fake-news-detect-1'\")\n",
    "\n",
    "dict(mv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "maxlen = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.texts_to_sequences(\"i am a boy\")\n",
    "tokens = sequence.pad_sequences(tokens, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 27s 187ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02289921],\n",
       "       [0.02186468],\n",
       "       [0.025014  ],\n",
       "       ...,\n",
       "       [0.02553978],\n",
       "       [0.02061237],\n",
       "       [0.02061237]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(predicted > 0.5, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_x=np.argmax(predicted,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 's3://my-mlflow-models-bucket'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlflow.keras.load_model(f'{loc}/421f9eff7a8a4ce89842c044d9fe6aad/artifacts/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 28s 184ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.0755357 ],\n",
       "       [0.07814227],\n",
       "       [0.07427611],\n",
       "       ...,\n",
       "       [0.07228513],\n",
       "       [0.10534022],\n",
       "       [0.10534022]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlflow.keras.load_model(\n",
    "    model_uri = model_uri, dst_path='./artifact'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/True.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.texts_to_sequences(df.iloc[0].text)\n",
    "tokens = sequence.pad_sequences(tokens, maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    0,  659],\n",
       "       [   0,    0,    0, ...,    0,    0, 2527],\n",
       "       [   0,    0,    0, ...,    0,    0,  241],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    0,    0, 1499],\n",
       "       [   0,    0,    0, ...,    0,    0,    4],\n",
       "       [   0,    0,    0, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/91 [===>..........................] - ETA: 14s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/thresh/MLOPS/final_mlops_zoomcamp/testing.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B24.199.64.104/home/thresh/MLOPS/final_mlops_zoomcamp/testing.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49m_model_impl\u001b[39m.\u001b[39;49mpredict(tokens)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/final_mlops_zoomcamp-IuAQxFwn/lib/python3.9/site-packages/mlflow/keras.py:511\u001b[0m, in \u001b[0;36m_KerasModelWrapper.predict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    508\u001b[0m             predicted \u001b[39m=\u001b[39m _predict(data)\n\u001b[1;32m    509\u001b[0m \u001b[39m# In TensorFlow >= 2.0, we do not use a graph and session to predict\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m     predicted \u001b[39m=\u001b[39m _predict(data)\n\u001b[1;32m    512\u001b[0m \u001b[39mreturn\u001b[39;00m predicted\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/final_mlops_zoomcamp-IuAQxFwn/lib/python3.9/site-packages/mlflow/keras.py:501\u001b[0m, in \u001b[0;36m_KerasModelWrapper.predict.<locals>._predict\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    499\u001b[0m     predicted\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mindex\n\u001b[1;32m    500\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 501\u001b[0m     predicted \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkeras_model\u001b[39m.\u001b[39;49mpredict(data)\n\u001b[1;32m    502\u001b[0m \u001b[39mreturn\u001b[39;00m predicted\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/final_mlops_zoomcamp-IuAQxFwn/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/final_mlops_zoomcamp-IuAQxFwn/lib/python3.9/site-packages/keras/engine/training.py:2334\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2332\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   2333\u001b[0m     callbacks\u001b[39m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 2334\u001b[0m     tmp_batch_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_function(iterator)\n\u001b[1;32m   2335\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   2336\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/final_mlops_zoomcamp-IuAQxFwn/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/final_mlops_zoomcamp-IuAQxFwn/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:897\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    894\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    896\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 897\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    899\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    900\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/final_mlops_zoomcamp-IuAQxFwn/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:936\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    934\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 936\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    937\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    938\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/final_mlops_zoomcamp-IuAQxFwn/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2468\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2465\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2466\u001b[0m   (graph_function,\n\u001b[1;32m   2467\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2468\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2469\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/final_mlops_zoomcamp-IuAQxFwn/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1834\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1830\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1831\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1832\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1833\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1834\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1835\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1836\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1837\u001b[0m     args,\n\u001b[1;32m   1838\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1839\u001b[0m     executing_eagerly)\n\u001b[1;32m   1840\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/final_mlops_zoomcamp-IuAQxFwn/lib/python3.9/site-packages/tensorflow/python/eager/function.py:479\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 479\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    480\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    481\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    482\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    483\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    484\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    485\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    486\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    487\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    488\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    491\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    492\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/final_mlops_zoomcamp-IuAQxFwn/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model._model_impl.predict(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('__class__', mlflow.pyfunc.PyFuncModel),\n",
       " ('__delattr__',\n",
       "  <method-wrapper '__delattr__' of PyFuncModel object at 0x7faefff1eee0>),\n",
       " ('__dict__',\n",
       "  {'_model_meta': <mlflow.models.model.Model at 0x7faf5d51bd90>,\n",
       "   '_model_impl': <mlflow.keras._KerasModelWrapper at 0x7faf6ddf9b80>}),\n",
       " ('__dir__', <function PyFuncModel.__dir__()>),\n",
       " ('__doc__',\n",
       "  \"\\n    MLflow 'python function' model.\\n\\n    Wrapper around model implementation and metadata. This class is not meant to be constructed\\n    directly. Instead, instances of this class are constructed and returned from\\n    :py:func:`load_model() <mlflow.pyfunc.load_model>`.\\n\\n    ``model_impl`` can be any Python object that implements the `Pyfunc interface\\n    <https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html#pyfunc-inference-api>`_, and is\\n    returned by invoking the model's ``loader_module``.\\n\\n    ``model_meta`` contains model metadata loaded from the MLmodel file.\\n    \"),\n",
       " ('__eq__', <method-wrapper '__eq__' of PyFuncModel object at 0x7faefff1eee0>),\n",
       " ('__format__', <function PyFuncModel.__format__(format_spec, /)>),\n",
       " ('__ge__', <method-wrapper '__ge__' of PyFuncModel object at 0x7faefff1eee0>),\n",
       " ('__getattribute__',\n",
       "  <method-wrapper '__getattribute__' of PyFuncModel object at 0x7faefff1eee0>),\n",
       " ('__gt__', <method-wrapper '__gt__' of PyFuncModel object at 0x7faefff1eee0>),\n",
       " ('__hash__',\n",
       "  <method-wrapper '__hash__' of PyFuncModel object at 0x7faefff1eee0>),\n",
       " ('__init__',\n",
       "  <bound method PyFuncModel.__init__ of mlflow.pyfunc.loaded_model:\n",
       "    artifact_path: model\n",
       "    flavor: mlflow.keras\n",
       "    run_id: d92d79a7278d4408b2406d82b2b09aab\n",
       "  >),\n",
       " ('__init_subclass__', <function PyFuncModel.__init_subclass__>),\n",
       " ('__le__', <method-wrapper '__le__' of PyFuncModel object at 0x7faefff1eee0>),\n",
       " ('__lt__', <method-wrapper '__lt__' of PyFuncModel object at 0x7faefff1eee0>),\n",
       " ('__module__', 'mlflow.pyfunc'),\n",
       " ('__ne__', <method-wrapper '__ne__' of PyFuncModel object at 0x7faefff1eee0>),\n",
       " ('__new__', <function object.__new__(*args, **kwargs)>),\n",
       " ('__reduce__', <function PyFuncModel.__reduce__()>),\n",
       " ('__reduce_ex__', <function PyFuncModel.__reduce_ex__(protocol, /)>),\n",
       " ('__repr__',\n",
       "  <bound method PyFuncModel.__repr__ of mlflow.pyfunc.loaded_model:\n",
       "    artifact_path: model\n",
       "    flavor: mlflow.keras\n",
       "    run_id: d92d79a7278d4408b2406d82b2b09aab\n",
       "  >),\n",
       " ('__setattr__',\n",
       "  <method-wrapper '__setattr__' of PyFuncModel object at 0x7faefff1eee0>),\n",
       " ('__sizeof__', <function PyFuncModel.__sizeof__()>),\n",
       " ('__str__',\n",
       "  <method-wrapper '__str__' of PyFuncModel object at 0x7faefff1eee0>),\n",
       " ('__subclasshook__', <function PyFuncModel.__subclasshook__>),\n",
       " ('__weakref__', None),\n",
       " ('_model_impl', <mlflow.keras._KerasModelWrapper at 0x7faf6ddf9b80>),\n",
       " ('_model_meta', <mlflow.models.model.Model at 0x7faf5d51bd90>),\n",
       " ('metadata', <mlflow.models.model.Model at 0x7faf5d51bd90>),\n",
       " ('predict',\n",
       "  <bound method PyFuncModel.predict of mlflow.pyfunc.loaded_model:\n",
       "    artifact_path: model\n",
       "    flavor: mlflow.keras\n",
       "    run_id: d92d79a7278d4408b2406d82b2b09aab\n",
       "  >)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getmembers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasWrapper(mlflow.pyfunc.PythonModel):\n",
    "  \n",
    "  def __init__(self, keras_model, labelEncoder, labelDecoder, n):         \n",
    "    self.keras_model = keras_model\n",
    "    self.labelEncoder = labelEncoder\n",
    "    self.labelDecoder = labelDecoder\n",
    "    self.topn = n\n",
    "    \n",
    "  def load_context(self, context): \n",
    "    self.keras_model = mlflow.keras.load_model(model_uri=context.artifacts[self.keras_model], compile=False)\n",
    "  \n",
    "  def predict(self, context, input_data):\n",
    "    scores = self.keras_model.predict(input_data)\n",
    "    return scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('final_mlops_zoomcamp-IuAQxFwn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c16c37569f787aed29b7c26c8cbe055204be9d66010cc533f8ef45c9cf8b88b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
